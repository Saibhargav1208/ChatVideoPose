# Pose-LLM Configuration

# Pose Estimation
pose:
  model_name: "mediapipe"  # Options: "mediapipe", "custom"
  confidence_threshold: 0.5
  extract_features: true
  feature_dim: 128
  max_frames: 300

# Positional Embedding
embedding:
  hidden_dim: 256
  dropout: 0.1
  max_position_embeddings: 512

# Q-Former
q_former:
  hidden_size: 768
  num_hidden_layers: 6
  num_attention_heads: 12
  intermediate_size: 3072
  dropout: 0.1
  num_query_tokens: 32

# Linear Layer
linear_layer:
  in_features: 768
  out_features: 1024

# LLM
llm:
  model_name: "llama-2-7b"  # Options: "llama-2-7b", "llama-2-13b", etc.
  max_length: 1024
  device: "cuda"  # Options: "cuda", "cpu"
  use_half_precision: true

# SMPL Token
smpl:
  num_tokens: 16
  dimension: 1024

# System
system:
  seed: 42
  output_dir: "outputs"
  cache_dir: "cache"
  device: "cuda"  # Options: "cuda", "cpu"
  debug: false